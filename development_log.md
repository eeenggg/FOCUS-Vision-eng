\# 📅 FOCUS Winter Camp 2026 开发日志 (Engineering Log)



\*\*作者：\*\* eeenggg

\*\*赛道：\*\* 视觉与云端 AI (Vision \& Cloud AI)

\*\*GitHub：\*\* https://github.com/eeenggg/FOCUS-WinterCamp-2026

\*\*记录周期：\*\* 2026.01.23 - 2026.01.29



---



\## 📍 Phase 1: 入门和基础



\### 1月23日：赛道分析与基座搭建

\* \*\*环境配置 (The Foundation)\*\*：

&nbsp;   \* 安装 Anaconda 管理 Python 环境，配置 PyTorch (GPU版) + CUDA 12.8。

&nbsp;   \* \*\*中间遇到的问题\*\*：

&nbsp;       \* \*问题\*：`pip install` 下载速度极慢，且经常断连。

&nbsp;       \* \*解决\*：配置了清华/阿里国内镜像源，速度提升至 10MB/s+。

&nbsp;       \* \*问题\*：安装错误版本的cuda导致无法启动

        \* \*解决\*：查询当前显卡适配的版本并重新安装

&nbsp;   \* \*\*Hello World\*\*：

&nbsp;       \* \[cite\_start]根据验收点 1 要求 \[cite: 219]，编写并提交了简单的 Hello World 脚本。

&nbsp;       \* 开启 GitHub Pages 功能，成功生成了个人介绍主页。



---



\## 📍 Phase 2: 理论学习

> \*\*阶段目标\*\*：不急于跑通 YOLO，而是先通过吴恩达课程夯实理论基础，同时补齐 Python 语法短板。



\### 1月24日 - 1月25日：Python 基础

\* \*\*基础学习\*\*：

&nbsp;   \* 根据指导书推荐的网课，大致熟悉了一遍python的语法。

\### 1月26日 - 1月27日：深度学习理论 (Deep Learning Specialization)

\* \*\*核心理论学习\*\*（基于吴恩达课程）：（说实在的没怎么真正理解）

&nbsp;   \* \*\*神经网络架构\*\*：从 Logistic Regression 推导到深层神经网络 (DNN)。

&nbsp;   \* \*\*反向传播 (Backpropagation)\*\*：可能理解了梯度下降算法如何通过链式法则更新权重 $w$ 和偏置 $b$。（也可能没怎么理解）

&nbsp;   \* \[cite\_start]\*\*CNN 原理\*\*：重点学习了卷积层 (Convolution) 提取特征、池化层 (Pooling) 降维的机制 \[cite: 269]。

\* \*\*核心概念攻克\*\*：（结合AI写的一点笔记）

&nbsp; \* \*\*向量化 (Vectorization)\*\*：

&nbsp;   \* \*理解\*：最初以为只是简单的数组操作，后来明白它是利用 SIMD 指令集进行 "并行批处理"。

&nbsp;   \* \*实战意义\*：消灭 `for` 循环。把 100 张图的预测从 "排队过安检" 变成了 "齐步走"，效率提升百倍。

&nbsp; \* \*\*梯度下降 (Gradient Descent)\*\*：

&nbsp;   \* \*感悟\*：通过 "下山找宝藏" 的比喻理解了学习率 (Learning Rate) 和 梯度 (Gradient) 的关系。梯度是方向盘，学习率是油门。

&nbsp;   \* \*反向传播\*：理解了链式法则本质上是一场 "连环追责"。误差从 Output 层传回 Input 层，根据 "谁激活得强" 和 "权重多大" 来分配责任 (Update Weights)。

\* \*\*卷积与池化\*\*：

&nbsp; \* \*\*卷积 (Conv)\*\*：不再是全连接的暴力计算，而是用 "过滤器 (Filter)" 像手电筒一样扫描图片提取特征。

&nbsp; \* \*\*池化 (Pooling)\*\*：理解了它不仅是为了减小尺寸（减负），更是为了提取 "最强特征"增加了容错）。

&nbsp; \* \*\*维度计算\*\*：$(N+2P-F)/S + 1$ 的输出尺寸计算公式。

\* \*\*激活函数的选择\*\*：

&nbsp; \* 对比了 Sigmoid 和 ReLU。明白了 Sigmoid 在深层网络中会导致 "梯度消失" (斜率接近0)，而 ReLU 提供了恒定的梯度流，是深层网络的基石。

\* \*\*疑问\*\*：为什么要搞跳跃连接 (Skip Connection)？

\* \*\*理解\*\*：

&nbsp; \* 这是一个 "保底机制"。主路负责提取特征，辅路 (Shortcut) 负责无损传输原始信息。

&nbsp; \* 就像给梯度修了 "高架桥"，即使网络堆到 100 层，梯度也能顺着辅路传回第一层，解决了退化问题。



\#### 关于Inception (GoogLeNet) 

\* \*\*痛点\*\*：不知道这一层该用 $3\\times3$ 还是 $5\\times5$ 卷积核。

\* \*\*解决方案\*\*：Inception 模块选择 "我全都要"。并行使用 $1\\times1, 3\\times3, 5\\times5$ 和池化，让 AI 自己去选最合适的特征组合。

\* \*\*关键技术：$1\\times1$ 卷积 (瓶颈层)\*\*：

&nbsp; \* \*开始时候的误区\*：以为只是像素乘法，没啥用，而且可能减慢速度。

&nbsp; \* \*学习后\*：发现它是 \*\*"降维神器"\*\*。在做昂贵的 $5\\times5$ 卷积前，先用 $1\\times1$ 把通道数 (Channels) 从 192 压到 16。

&nbsp; \* \*对比\*：计算量从 1.2 亿次 骤降到 1200 万次。Inception 用 "多分支结构" 换取了适应性，用 "$1\\times1$ 瓶颈" 换取了速度。



\## 📍 Phase 3: 自定义数据集实战 (1.28)

> \*\*挑战\*\*：尝试让AI能分辨出mygo的五人以及分辨出四种常见的物品。



\### 1月28日：

\* \*\*数据采集\*\*：

&nbsp;   \* 收集了 MyGO 乐队成员的动画截图与同人图

&nbsp;   \* \*\*难点\*\*：二次元画风与现实世界差异大（Domain Shift），且部分角色（如灯和立希）发色接近，模型极易混淆。且灯的头发颜色在不同时期的官图以及同人图里并不统一。

\* \*\*数据标注\*\*：

&nbsp;   \* 使用 `labelImg` 工具进行人工标注，导出 YOLO 格式 (.txt) 标签。

&nbsp;   \* \*Trick\*：针对遮挡严重的样本进行了更精细的标注框调整。



\### 模型训练迭代 (Model Iteration)

\* \*\*V1.0 (Nano 模型)\*\*：

&nbsp;   \* 使用 `yolo11n.pt` 训练。结果：效果不好，容易认错，

\* \*\*V2.0 (Medium 模型 - 最终版)\*\*：

&nbsp;   \* \[cite\_start]\*\*调整\*\*：切换至参数量更大的 `yolo11m.pt` \[cite: 358]。

&nbsp;   \* \*\*参数调优\*\*：

&nbsp;       \* `epochs=100`：保证充分收敛。

&nbsp;       \* `batch=4`：防止显存溢出。

&nbsp;   \* \*\*结果\*\*：训练生成的 `train9` 模型，\*\*mAP@0.5 升至 0.995\*\*。效果增强（实际效果也没有很强，数据集内的倒是没问题，数据集外的五人合影容易混淆，单人图片尚且可以。）



---



\## 📍 Phase 4:验收任务

\### 1月29日：



\### 上午：视频人物计数 (Video Counting)

\* \[cite\_start]\*\*目标\*\*：统计视频中的人数 \[cite: 303]。

\* \*\*遭遇重大报错\*\*：

&nbsp;   \* \*现象\*：运行脚本时报错 `RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory`。

&nbsp;   \* \*排查\*：检查 `src/scripts` 目录，发现自动下载的 `yolo11m.pt` 只有 0KB。推测是网络波动导致下载中断，文件损坏。

&nbsp;   \* \*解决\*：删除损坏文件，通过浏览器手动下载完整权重包并导入，问题瞬间解决。

\* \*\*可视化优化\*\*：

&nbsp;   \* 初始版本的计数文字太小且颜色不明显。

&nbsp;   \* \*优化代码\*：调整 `cv2.putText` 参数，将字体缩放至 `1.2`，颜色改为醒目的红色 `(0, 0, 255)`，并增加了自动保存结果视频的功能。



\### 下午：补充一个识别杯子，手表，鼠标，手帕纸的模型

\* \*\*过程\*\*：

&nbsp;   \* 拍摄 22 张照片 -> `labelImg` 快速标注 -> 编写 `common\_obj.yaml`。

&nbsp;   \* \*\*训练\*\*：运行 `train\_common.py`，生成 `train\_common2` 权重，成功识别所有物品。



\### 晚上：整理文件夹





